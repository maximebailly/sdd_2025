{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC5 - Sélection de modèle et régularisation - 27 juin 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons utiliser des données simulées pour mieux comprendre les __régularisations L1 et L2__. Ce sera aussi l'occasion de mettre en place une __recherche sur grille__ pour sélectionner le coefficient de régularisation par validation croisée. \n",
    "\n",
    "Dans la dernière partie, vous pourrez mettre en œuvre ces algorithmes sur un jeu de données réelles.\n",
    "\n",
    "Ce notebook sera aussi l'occasion d'aborder un premier algorithme d'apprentissage supervisé _non-linéaire_, la __régression polynomiale__.\n",
    "\n",
    "Ce notebook a été initialement proposé par [Arthur Imbert](https://github.com/Henley13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de numpy et matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fixe ici la graine pour le générateur de nombres aléatoires, pour faciliter la reproducibilité\n",
    "np.random.seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Régularisation L2 (ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simulation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par simuler un jeu de données de 30 échantillons avec une seule variable prédictive (p=1) et dans lequel l'étiquette est une fonction non-linéaire (sinusoïdale) de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 30\n",
    "\n",
    "# vrai modèle (Y = true_f(X))\n",
    "def true_f(x):\n",
    "    return np.cos(1.5 * np.pi * x) * 5\n",
    "\n",
    "# tirer nb_samples valeurs de x entre 0 et 1\n",
    "X = np.random.rand(nb_samples, 1)\n",
    "y = true_f(X)\n",
    "\n",
    "# ajouter du bruit\n",
    "y += np.random.randn(nb_samples, 1) * 0.3\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant visualiser ce que nous venons de simuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Pour afficher le vrai modèle :\n",
    "# créer 100 points de vraies paires (x, y) \n",
    "# créer un array de dimension (1, 100) contenant 100 valeurs régulièrement espacées entre 0 et 1  \n",
    "X_grid = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "# calculer leurs étiquettes\n",
    "y_true = true_f(X_grid)\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X, y, label=\"observations simulées\", color=\"tab:blue\", marker=\"+\", s=50)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "\n",
    "plt.title(\"Vrai modèle et données simulées\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant séparer nos données en un jeu d'entraînement et un jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant de la PC4, séparer (`X`, `y`) en un jeu d'entraînement (`X_train`, `y_train`) et un jeu de test (`X_test`, `y_test`). Le jeu de test contiendra 30% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Reproduire le graphique précédent, mais distinguer jeu d'entraînement (+) et jeu de test (x) parmi les observations simulées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Régression linéaire classique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant de la PC4, entraîner une régression linéaire sur `(X_train, y_train)`. Appeler le modèle `linreg`.\n",
    "\n",
    "Remarquez que les variables ayant été générées centrées-réduites, il n'est pas nécessaire de leur appliquer cette transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons écrire explicitement le modèle appris en accédant à ses coefficients :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L'équation du modèle appris est : y = {linreg.coef_[0][0]:.2f} x + {linreg.intercept_[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer le [coefficient de détermination](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) de `linreg` sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi comparer ces deux performances ? Qu'en conclure ici ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Si la performance est moins bonne sur le jeu de test, cela indique une situation de sur-apprentissage. À l'inverse, si la performance est meilleure sur le jeu de test, cela indique un sous-apprentissage.\n",
    "\n",
    "Ici, le modèle sous-apprend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ La différence entre les performances va dépendre d'où sont situées les observations de chacun des deux jeux.\n",
    "\n",
    "Par exemple, si tous les points du jeu d'entraînement sont situés entre $x=0,2$ et $x=0,6$, le modèle est bien approché par une droite et la performance sur le jeu d'entraînement sera bonne. Cette droite est une mauvaise approximation de ce qui se passe à l'extérieur de cet intervalle, si le jeu de test contient des points qui s'y trouvent, la performance sera fortement dégradée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter au graphique précédent le modèle appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Régression polynomiale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons jusqu'à présent travaillé avec une seule variable.\n",
    "\n",
    "Pour essayer d'améliorer notre modèle, nous pouvons _créer de nouvelles variables_ à partir de celle-ci (par exemple $x^2+x^3$, $\\log(x)$, $e^{x-17}$) et apprendre un modèle linéaire sur ces nouvelles variables. Plutôt que de procéder à tatons comme dans les exemples entre parenthèse, on peut se limiter aux _puissances_ de notre variable $x$.\n",
    "\n",
    "Ainsi, nous allons remplacer l'unique variable $x$ par $d$ variables $x, x^2, x^3, \\dots, x^d$. Apprendre une fonction linéaire de ces $d$ variables est équivalent à apprendre un polynôme de degré $d$ de $x$. C'est une première approche pour apprendre un modèle non linéaire !\n",
    "\n",
    "Cette idée se généralise à un nombre arbitraire de variables initiales ; on crée alors tous les _monomes_ de degré au plus $d$ de ces variables : $(x_1, x_2, \\dots, x_p)$ devient $(x_1, x_2, \\dots, x_p, x_1^2, x_1 x_2, \\dots, x_p^d)$. On parle alors de _régression polynomiale_. Nous en reparlerons dans le chapitre 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans scikit-learn, la classe [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) du module `preprocessing` permet de créer ces nouvelles variables, ce que nous allons faire ici pour un degré $d$=15 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet permettant de créer des variables polynomiales de degré au plus 15\n",
    "polynomial_features = preprocessing.PolynomialFeatures(degree=15, include_bias=False)\n",
    "\n",
    "# Appliquer cet objet aux variables de X_train \n",
    "X_train_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "# Appliquer la même transformation aux données de test\n",
    "X_test_poly = polynomial_features.transform(X_test)\n",
    "\n",
    "# Ainsi qu'à la grille de points servant à appliquer le modèle sur tout [0, 1]\n",
    "X_grid_poly = polynomial_features.transform(X_grid)\n",
    "\n",
    "print(X_train_poly.shape, X_test_poly.shape, X_grid_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien de variables avons-nous maintenant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entraîner maintenant une régression polynomiale `polyreg` sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est maintenant l'équation du modèle appris ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que dire de ces coefficients ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__  Calculer le coefficient de détermination de la régression polynomiale sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le coefficient de régression de polyreg sur le jeu d'entraînement\n",
    "polyreg_r2_train = metrics.r2_score(y_train, polyreg.predict(X_train_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu d'entraînement : {polyreg_r2_train:.2f}.\")\n",
    "\n",
    "# Calculer le coefficient de régression de polyreg sur le jeu de test\n",
    "polyreg_r2_test = metrics.r2_score(y_test, polyreg.predict(X_test_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu de test : {polyreg_r2_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression polynomiale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Le modèle surapprend. Les performances du jeu d'entraînement sont bien supérieures à celles du jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Remplacer sur le graphique précédent le modèle appris par régression linéaire par celui  appris par régression polynomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Régression polynomiale régularisée ridge\n",
    "\n",
    "Comme la régression polynomiale surapprend, nous allons maintenant lui appliquer un terme de __régularisation ridge (L2)__ pour essayer de compenser cet effet :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier une régression linéaire avec régularisation ridge avec un coefficient de régularisation valant 0.01\n",
    "polyreg_ridge = linear_model.Ridge(alpha=0.01, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Utiliser `polyreg_ridge` pour entraîner une régression polynomiale avec régularisation L2 sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est l'équation de ce modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer ces coefficients à ceux du modèle appris sans régularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer le coefficient de détermination de la régression polynomiale avec régularisation ridge sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pensez-vous que le modèle surapprend toujours ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher maintenant ce nouveau modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comment aurait-on pu essayer d'éviter le surapprentissage avec une régression polynomiale mais sans régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Régularisation L1 (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simulation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par simuler un jeu de données de 60 échantillons avec 100 variables, et dans lequel l'étiquette est une fonction linéaire de seulement 10 de ces variables, les autres étant du bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 60\n",
    "nb_features = 100\n",
    "\n",
    "# créer un jeu de données aux dimensions demandées à partir d'une loi normale centrée-réduite\n",
    "X = np.random.randn(nb_samples, nb_features)\n",
    "\n",
    "# créer un vecteur de coefficients nuls\n",
    "beta = np.zeros(nb_features)\n",
    "\n",
    "# créer des coefficients pour les 10 premières variables\n",
    "#   (pour faciliter la visualisation,\n",
    "#   décroissants en valeur absolue, avec alternance de signe)\n",
    "beta[:10] = [((-1) ** idx * np.exp(-idx/10)) for idx in range(10)]\n",
    "\n",
    "# créer les étiquettes\n",
    "y = np.dot(X, beta) + np.random.randn(nb_samples) * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons les coefficients du modèle ayant permis de simuler les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.stem(np.arange(nb_features), beta, markerfmt='o', \n",
    "         linefmt='tab:blue',\n",
    "         label='vrais coefficients')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.title(\"Modèle parcimonieux\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Séparer (`X`, `y`) en un jeu d'entraînement (`X_train`, `y_train`) et un jeu de test (`X_test`, `y_test`). Le jeu de test contiendra 30% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrélation entre les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La difficulté pour l'apprentissage est double :\n",
    "- seule une faible proportion des variables influencent l'étiquette\n",
    "- le nombre d'observations est faible par rapport à ce nombre de variables.\n",
    "\n",
    "Un des problèmes qui apparait quand on a plus de variables que d'observations est que les variables peuvent apparaître corrélées même quand elles ne le sont pas. Affichons ici la matrice de corrélation entre les variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corrélation deux à deux\n",
    "df = pd.DataFrame(X_train)\n",
    "X_train_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(X_train_corr, annot=False, \n",
    "            vmin=-1, vmax=1, center=0, # bornes de la barre de couleurs\n",
    "            cmap='PuOr', linewidths=0.5)\n",
    "plt.title(\"Corrélation entre les variables de X_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Commenter cette matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entraîner sur (`X_train, y_train`) une régression linéaire classique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Évaluer la RMSE de cette régression linéaire sur le jeu d'entraînement et sur le jeu de test. La régression linéaire a-t-elle une performance satisfaisante ? Y-a-t'il un risque de sur- ou de sous-apprentissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il y a manifestement surapprentissage, la performance sur le jeu d'entraînement étant parfaite mais pas sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ La performance sur le jeu d'entraînement est-elle surprenante ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter à la visualisation des poids du modèle les coefficients appris par la régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients appris aux vrais coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entrainez un Lasso avec comme paramètre de régularisation `alpha=0.01` sur les données d'entraînement en utilisant la classe [`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) du module `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Évaluer la RMSE de ce lasso sur le jeu d'entraînement et sur le jeu de test. Y-a-t'il a un risque de sur- ou de sous-apprentissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il semble toujours y avoir du surapprentissage, mais moins que précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter à la visualisation des poids du modèle les coefficients appris par le lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients appris aux vrais coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sélection de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jusqu'à présent fixé la valeur du coefficient de régularisation (`alpha` dans `scikit-learn`, $\\lambda$ dans le poly). Nous allons maintenant voir comment utiliser une recherche sur grille dans le cadre d'une validation croisée pour _sélectionner_ la valeur de ce coefficient, qui est un _hyperparmètre_ du lasso.\n",
    "\n",
    "Nous travaillons toujours avec les données de la section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe `KFold` du module `model_selection` de scikit-learn permet de créer des _folds_ de validation croisée, c'est-à-dire de diviser un jeu de données en K blocs et de constituer K paires de jeux d'entraînement et de validation, où le jeu de validation est l'un des blocs et le jeu d'entraînement est l'union des (K-1) autres blocs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantier un objet KFold \n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `kf.split()` permet maintenant de partager un jeu de données en 5 folds. Attention, elle retourne un générateur, sur lequel on ne peut itérer qu'une fois. Fixer la valeur de `random_state` permet d'avoir la même partition à chaque appel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_indices, val_indices) in enumerate(kf.split(X_train)):\n",
    "    print(f\"fold: {i} : {len(train_indices)} observations pour l'entraînement et {len(val_indices)} pour la validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Compléter le code suivant pour déterminer la RMSE en validation croisée (c'est-à-dire la performance moyenne sur les 5 jeux de validation) d'un lasso avec coefficient de régularisation `alpha=0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle à évaluer\n",
    "lasso = ...\n",
    "\n",
    "rmse_list = []\n",
    "# Boucler sur les folds :\n",
    "for i, (train_indices, val_indices) in enumerate(kf.split(X_train)):\n",
    "    print(f\"fold: {i} : {len(train_indices)} observations pour l'entraînement et {len(val_indices)} pour la validation.\")\n",
    "\n",
    "    # créer le jeu d'entraînement et le jeu de validation pour ce fold\n",
    "    X_train_fold = ...\n",
    "    y_train_fold = ...\n",
    "    X_test_fold = ...\n",
    "    y_test_fold = ...\n",
    "\n",
    "    # entraîner le modèle sur le jeu d'entraînement de ce fold\n",
    "    lasso.fit(...)\n",
    "\n",
    "    # prédire sur le jeu de validation du fold\n",
    "    rmse_fold = ...\n",
    "    rmse_list.append(rmse_fold)\n",
    "    print(f\"\\tRMSE (test) : {rmse:.2f}\")\n",
    "\n",
    "# Moyenner les performances\n",
    "rmse_average = np.mean(rmse_list)                    \n",
    "print(f\"La RMSE moyenne du Lasso (alpha=0.1) est de {rmse_average:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn peut faire cette opération directement avec la fonction `cross_validate` du module `model_selection` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_scores = model_selection.cross_val_score(lasso, X_train, y_train, \n",
    "                                                  cv=kf, # utiliser les folds déjà définis \n",
    "                                                  scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que l'on obtient bien les mêmes résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La RMSE moyenne du Lasso (alpha=0.01) est de {-np.mean(lasso_cv_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi est-ce `neg_root_mean_squared_error`, qui retourne _l'opposé_ de la RMSE, qui est implémentée comme fonction de score et non pas directement la RMSE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Ces scores sont utilisés pour sélectionner le meilleur modèle, qui sera celui qui a le score de performance le plus élevé. Dans le cas de la RMSE, il s'agit donc de celui qui a la plus petite RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recherche sur grille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La _recherche sur grille_ (_gridsearch_) consiste à comparer différentes valeurs d'une grille d'hyperparamètres en comparant la performance des modèles appris avec chacune de ces valeurs, généralement en utilisant une validation croisée.\n",
    "\n",
    "Dans scikit-learn, cette procédure est implémentée dans la classe `GridSearchCV` de `model_selection` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille de valeurs de l'hyperparamètre alpha \n",
    "alphas = np.logspace(-5, 1, 40)\n",
    "\n",
    "# Définir le modèle à évaluer\n",
    "lasso = linear_model.Lasso(random_state=13, \n",
    "                           max_iter=10000 # pour assurer la convergence (warning sinon)\n",
    "                          )\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid = model_selection.GridSearchCV(lasso, {'alpha': alphas}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='neg_root_mean_squared_error'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valeur de la RMSE en fonction de alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les détails des calculs effectués par `fit` sont accessibles dans le dictionnaire retourné par `grid.cv_results_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi récupérer les scores obtenus pour chaque valeur de `alpha` et les représenter sur une figure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "rmses = -grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE avec une échelle logarithmique pour les abscisses :\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses, \n",
    "             label=\"lasso\", color='tab:blue')\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(alphas, (rmses + std_error), (rmses - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE +/- un écart-type\")\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Recherche sur grille (Lasso)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ À quoi correspond un modèle avec une faible valeur de `alpha` ? Une valeur élevée de `alpha` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs optimales de la recherche sur grille et le score correspondant sont données par les paramètres`best_params_` et `best_score_` de l'objet de la classe `GridSearchCV` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La meilleure valeur de alpha est : {grid.best_params_['alpha']:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher ce point sur la courbe précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le modèle correspondant, ré-entraîné sur l'ensemble des données passées à la fonction `fit`, est donné par le paramètre `best_estimator_`. Comparez sur une figure ses coefficients à ceux du vrai modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce cas pratique nous utilisons des données cliniques. L'objectif est de **prédire le niveau d'antigène prostatique spécifique** (ou *PSA* pour *Prostate-Specific Antigen*). C'est une protéine produite exclusivement par la prostate. Un taux de concentration élevé de cette molécule dans le sang est souvent le signe chez l'homme d'un cancer de la prostate. Cet indicateur permet ainsi de suivre l'évolution d'un tel cancer.\n",
    "\n",
    "Plus précisément, nous allons essayer de prédire le niveau de concentration du *PSA* (`lpsa`, en échelle logarithmique) à partir des mesures cliniques suivantes :\n",
    "- `cavol` : Le volume de la tumeur (échelle logarithmique).\n",
    "- `lweight` : Le poids de la prostate (échelle logarithmique).\n",
    "- `age`: L'âge du patient.\n",
    "- `lbph`: Le volume de l'hypertrophie bénigne de la prostate (*BPH* pour *Benign Prostatic Hyperplasia*) qui correspond au volume non cancéreux de l'organe (échelle logarithmique).\n",
    "- `svi`: Indicateur sur le fait que le cancer s'est propagé aux vésicules séminales (deux glandes associées à la prostate).\n",
    "- `lcp`: La *pénétration capsulaire* qui mesure à quel point la capsule prostatique (la membrane qui entoure la prostate), a été envahi par le cancer (échelle logarithmique).\n",
    "- `gleason`: Le score de *Gleason*. Ce score est établi par un histopathologiste après observation d'une biopsie de la prostate. Pour plus d'information vous pouvez consulter ce lien : http://www.wikiwand.com/en/Gleason_grading_system. \n",
    "* `pgg45`: Le pourcentage de la tumeur qui est accrédité d'un score *Gleason* de 4 ou 5.\n",
    "\n",
    "Ce jeu de données est un jeu de données classique, que l'on trouve par exemple [sur Kaggle](https://www.kaggle.com/tvscitechtalk/prostatecsv). Il est issu de Stamey, T.A., Kabalin, J.N., McNeal, J.E., Johnstone, I.M., Freiha, F., Redwine, E.A. and Yang, N. (1989). Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate: II. radical prostatectomy treated patients, _Journal of Urology_ 141(5), 1076–1083.\n",
    "\n",
    "Nous avons bien ici un problème de **régression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/prostate.csv\", index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons extraire de ce dataframe une matrice `X` de données et un vecteur `y` d'étiquettes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, [\"lcavol\", \"lweight\", \"age\", \"lbph\", \"svi\", \"lcp\", \"gleason\", \"pgg45\"]].to_numpy()\n",
    "y = df.loc[:, \"lpsa\"].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Séparer ce jeu de données en un jeu d'entraînement et un jeu de test (contenant 30% des observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for train and test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En vous inspirant de la PC4, centrez et réduisez les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Régression linéaire non régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer la RMSE d'une régression linéaire en validation croisée sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En utilisant une validation croisée sur le jeu d'entraînement, effectuez une recherche sur une grille de valeurs entre $10^{-3}$ et $10^5$ du meilleur coefficient de régularisation pour une régression ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la valeur optimale de RMSE obtenue ? Pour quelle valeur de coefficient de régularisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher l'évolution de la RMSE en fonction de la valeur du coefficient de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher les coefficients de la meilleure régression ridge. Quelles variables paraissent plus pertinentes pour la prédiction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les variables les plus pertinentes semblent être `lcavol`, `lweight` et `svi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En utilisant une validation croisée sur le jeu d'entraînement, effectuez une recherche sur une grille de valeurs entre $10^{-4}$ et $10^2$ du meilleur coefficient de régularisation pour un lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la valeur optimale de RMSE obtenue ? Pour quelle valeur de coefficient de régularisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher l'évolution de la RMSE en fonction de la valeur du coefficient de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher sur le même graphique les coefficients de la meilleure régression ridge et ceux du meilleur lasso. Quelles variables paraissent plus pertinentes pour la prédiction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer ces deux modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est le meilleur modèle ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle performance peut-on espérer de ce modèle sur de nouvelles données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
